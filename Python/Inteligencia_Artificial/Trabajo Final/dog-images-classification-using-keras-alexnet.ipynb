{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note this kernel is for practice purposes only.** <br><br>\n",
    "In this kernel I will be using [AlexNet](https://en.wikipedia.org/wiki/AlexNet) for multiclass image classification.\n",
    "\n",
    "**Inferences from the given dataset description:**<br>\n",
    "- There are 20,580 dogs images divided into 120 different categories (i.e., 120 breeds of dogs)\n",
    "\n",
    "**Steps followed in this kernel:**\n",
    "- Pick different categories of dog images for training the CNN model.\n",
    "- After the training is done we will check the accuracy of the CNN model in predicting the dog's breed correctly given an image of the dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ff27b6a21da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "print(\"Loaded all libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data loading and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "fpath = \"../input/images/Images/\"\n",
    "random_seed = 42\n",
    "\n",
    "categories = os.listdir(fpath)\n",
    "categories = categories[:20]\n",
    "print(\"List of categories = \",categories,\"\\n\\nNo. of categories = \", len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(categories):\n",
    "    img_lst=[]\n",
    "    labels=[]\n",
    "    for index, category in enumerate(categories):\n",
    "        for image_name in os.listdir(fpath+\"/\"+category):\n",
    "            img = cv2.imread(fpath+\"/\"+category+\"/\"+image_name)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            img_array = Image.fromarray(img, 'RGB')\n",
    "            \n",
    "            #resize image to 227 x 227 because the input image resolution for AlexNet is 227 x 227\n",
    "            resized_img = img_array.resize((227, 227))\n",
    "            \n",
    "            img_lst.append(np.array(resized_img))\n",
    "            \n",
    "            labels.append(index)\n",
    "    return img_lst, labels\n",
    "\n",
    "images, labels = load_images_and_labels(categories)\n",
    "print(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check few random images and labels by displaying them in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_rand_images(images, labels):\n",
    "    plt.figure(1 , figsize = (19 , 10))\n",
    "    n = 0 \n",
    "    for i in range(9):\n",
    "        n += 1 \n",
    "        r = np.random.randint(0 , images.shape[0] , 1)\n",
    "        \n",
    "        plt.subplot(3 , 3 , n)\n",
    "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
    "        plt.imshow(images[r[0]])\n",
    "        \n",
    "        plt.title('Dog breed : {}'.format(labels[r[0]]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "display_rand_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare data for training the CNN model\n",
    "\n",
    "- For training the CNN model we have to shuffle all the data that is loaded in images, labels list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-step in data shuffling\n",
    "\n",
    "#get equally spaced numbers in a given range\n",
    "n = np.arange(images.shape[0])\n",
    "print(\"'n' values before shuffling = \",n)\n",
    "\n",
    "#shuffle all the equally spaced values in list 'n'\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(n)\n",
    "print(\"\\n'n' values after shuffling = \",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-step in data shuffling\n",
    "\n",
    "#shuffle images and corresponding labels data in both the lists\n",
    "images = images[n]\n",
    "labels = labels[n]\n",
    "\n",
    "print(\"Images shape after shuffling = \",images.shape,\"\\nLabels shape after shuffling = \",labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float32)\n",
    "labels = labels.astype(np.int32)\n",
    "images = images/255\n",
    "print(\"Images shape after normalization = \",images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display few random images after data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_rand_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the loaded dataset into train, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = random_seed)\n",
    "\n",
    "print(\"x_train shape = \",x_train.shape)\n",
    "print(\"y_train shape = \",y_train.shape)\n",
    "print(\"\\nx_test shape = \",x_test.shape)\n",
    "print(\"y_test shape = \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_rand_images(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define AlexNet CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define all layers in the AlexNet CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#1 conv layer\n",
    "model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\n",
    "\n",
    "#1 max pool layer\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#2 conv layer\n",
    "model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "#2 max pool layer\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#3 conv layer\n",
    "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "#4 conv layer\n",
    "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "#5 conv layer\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "\n",
    "#3 max pool layer\n",
    "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#1 dense layer\n",
    "model.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#2 dense layer\n",
    "model.add(Dense(4096,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#3 dense layer\n",
    "model.add(Dense(1000,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(20,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compile the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metrics to evaluate accuracy and loss in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict values using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display few random images with actual vs predicted values of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (19 , 10))\n",
    "n = 0 \n",
    "\n",
    "for i in range(9):\n",
    "    n += 1 \n",
    "    r = np.random.randint( 0, x_test.shape[0], 1)\n",
    "    \n",
    "    plt.subplot(3, 3, n)\n",
    "    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "    \n",
    "    plt.imshow(x_test[r[0]])\n",
    "    plt.title('Actual = {}, Predicted = {}'.format(y_test[r[0]] , y_test[r[0]]*pred[r[0]][y_test[r[0]]]) )\n",
    "    plt.xticks([]) , plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
